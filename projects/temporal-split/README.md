# Data Leakage Temporal: Train/Test Split Correcto

## ğŸ“š DescripciÃ³n

Este proyecto ilustra uno de los errores mÃ¡s comunes y peligrosos en machine learning aplicado a datos temporales: **usar train/test split aleatorio cuando los datos tienen una dimensiÃ³n temporal**.

## ğŸ¯ Objetivo de Aprendizaje

Comprender que:
- Los datos con componente temporal requieren un split especial
- El split aleatorio tradicional causa **data leakage temporal**
- Las mÃ©tricas pueden ser artificialmente optimistas si no se respeta el orden temporal
- El desempeÃ±o real en producciÃ³n puede ser mucho peor de lo esperado

## ğŸ“– TeorÃ­a: Data Leakage Temporal

### Â¿QuÃ© es Data Leakage?

**Data leakage** (fuga de datos) ocurre cuando informaciÃ³n del conjunto de test "se filtra" al conjunto de entrenamiento, permitiendo que el modelo aprenda patrones que no estarÃ­an disponibles en un escenario real de predicciÃ³n.

### El Problema EspecÃ­fico con Datos Temporales

En muchos problemas de machine learning, los datos tienen una **dimensiÃ³n temporal**:
- Transacciones financieras con timestamps
- Ventas diarias/mensuales
- Logs de sistemas
- MÃ©tricas de sensores
- Series de tiempo en general

**Â¿QuÃ© ocurre con un split aleatorio?**

```python
# âŒ INCORRECTO
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, shuffle=True  # shuffle=True es el problema
)
```

Al mezclar aleatoriamente, podemos tener:
- Datos de **diciembre 2023** en el conjunto de entrenamiento
- Datos de **enero 2023** en el conjunto de test

**Consecuencia**: El modelo aprende del "futuro" (diciembre) para predecir el "pasado" (enero).

### Â¿Por quÃ© es tan peligroso?

1. **MÃ©tricas infladas**: El modelo parece funcionar mejor de lo que realmente funcionarÃ¡ en producciÃ³n
2. **Falsa confianza**: Tomamos decisiones basadas en mÃ©tricas que no reflejan la realidad
3. **Fallo en producciÃ³n**: Al desplegar, el modelo solo conoce el pasado, no el futuro
4. **Impacto en negocio**: Predicciones incorrectas pueden costar dinero real

### Ejemplo Concreto

Imagina que predices ventas de un producto:

**Con split aleatorio (incorrecto):**
- Tu modelo aprende que las ventas en diciembre son altas (temporada navideÃ±a)
- Cuando predice ventas de octubre (que estÃ¡ en test), usa informaciÃ³n de diciembre
- MÃ©tricas: RÂ² = 0.95 (Â¡excelente!)

**En producciÃ³n:**
- En octubre, el modelo NO conoce diciembre todavÃ­a
- Las predicciones son malas porque el modelo dependÃ­a de informaciÃ³n futura
- DesempeÃ±o real: RÂ² = 0.65 (mediocre)

## ğŸ”§ La SoluciÃ³n: Split Temporal

### Principio Fundamental

> **El conjunto de entrenamiento debe contener SOLO datos anteriores al conjunto de test**

Esto simula el escenario real donde:
- Aprendemos del **pasado** (train)
- Predecimos el **futuro** (test)

### ImplementaciÃ³n Correcta

```python
# âœ… CORRECTO: Split temporal manual
split_point = int(len(df) * 0.7)

X_train = X.iloc[:split_point]      # Primeros 70% (datos antiguos)
X_test = X.iloc[split_point:]       # Ãšltimos 30% (datos recientes)
y_train = y.iloc[:split_point]
y_test = y.iloc[split_point:]
```

### VisualizaciÃ³n del Concepto

```
LÃ­nea de tiempo: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶
                 2022-01-01          2023-12-31

Split Aleatorio (INCORRECTO):
Train:  â–ˆâ–ˆâ–‘â–‘â–ˆâ–ˆâ–‘â–‘â–‘â–ˆâ–ˆâ–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–ˆâ–ˆ
Test:   â–‘â–‘â–ˆâ–ˆâ–‘â–‘â–ˆâ–ˆâ–ˆâ–‘â–‘â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–‘â–‘â–‘â–‘

Split Temporal (CORRECTO):
Train:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘
Test:   â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
                         â†‘
                    Punto de corte
```

## ğŸ› ï¸ Herramientas para Split Temporal

### 1. Split Manual (Recomendado para simplicidad)

```python
# Basado en porcentaje
split_idx = int(len(df) * 0.7)
train = df.iloc[:split_idx]
test = df.iloc[split_idx:]
```

```python
# Basado en fecha especÃ­fica
cutoff_date = '2023-06-01'
train = df[df['fecha'] < cutoff_date]
test = df[df['fecha'] >= cutoff_date]
```

### 2. TimeSeriesSplit (Para validaciÃ³n cruzada)

```python
from sklearn.model_selection import TimeSeriesSplit

tscv = TimeSeriesSplit(n_splits=5)
for train_idx, test_idx in tscv.split(X):
    X_train, X_test = X[train_idx], X[test_idx]
    y_train, y_test = y[train_idx], y[test_idx]
    # Entrenar y evaluar
```

**Ventaja**: Permite validaciÃ³n cruzada respetando el orden temporal.

**CÃ³mo funciona**:
```
Split 1: [Train: â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] [Test: â–‘â–‘â–‘â–‘â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘]
Split 2: [Train: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘] [Test: â–‘â–‘â–‘â–‘â–‘â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘]
Split 3: [Train: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘] [Test: â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–‘â–‘â–‘â–‘â–‘]
Split 4: [Train: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘] [Test: â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–‘â–‘â–‘â–‘]
Split 5: [Train: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘] [Test: â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–‘â–‘â–‘]
```

Cada test siempre es posterior a su correspondiente train.

## ğŸ“Š ComparaciÃ³n de Resultados

### Resultados TÃ­picos

| MÃ©trica | Split Aleatorio | Split Temporal | Diferencia |
|---------|----------------|----------------|------------|
| RÂ² | 0.92 | 0.68 | -26% |
| MAE | 8.5 | 14.2 | +67% |
| RMSE | 11.3 | 18.7 | +65% |

El split aleatorio **sobreestima** significativamente el desempeÃ±o.

## ğŸ“ Casos de Uso Donde Esto es CrÃ­tico

1. **PredicciÃ³n de ventas/demanda**
   - Forecasting de inventario
   - PlanificaciÃ³n de producciÃ³n

2. **Trading algorÃ­tmico**
   - PredicciÃ³n de precios de acciones
   - Backtesting de estrategias

3. **DetecciÃ³n de fraude**
   - Transacciones ordenadas temporalmente
   - Patrones que evolucionan con el tiempo

4. **Mantenimiento predictivo**
   - Logs de sensores en mÃ¡quinas
   - PredicciÃ³n de fallos

5. **Marketing digital**
   - PredicciÃ³n de conversiones
   - Comportamiento de usuarios en el tiempo

6. **Forecasting climÃ¡tico**
   - PredicciÃ³n de temperatura
   - PronÃ³stico de lluvias

## âš ï¸ SeÃ±ales de Alerta

Debes sospechar de data leakage temporal si:

1. **RÂ² muy alto** (>0.95) en problemas complejos de series de tiempo
2. **Gran diferencia** entre mÃ©tricas de validaciÃ³n y producciÃ³n
3. **Features con informaciÃ³n futura** (ej: promedios que incluyen el valor a predecir)
4. **Lag features calculados incorrectamente** (usando valores futuros)

## ğŸ” Otras Consideraciones

### Gap entre Train y Test

En algunos casos, puedes querer dejar un **gap** (espacio) entre train y test:

```python
# Dejar 7 dÃ­as de gap
train_end = int(len(df) * 0.7)
gap = 7
test_start = train_end + gap

X_train = X.iloc[:train_end]
X_test = X.iloc[test_start:]
```

**RazÃ³n**: Simular latencia en obtenciÃ³n de datos o evitar dependencias inmediatas.

### Walk-Forward Validation

Para sistemas de trading y producciÃ³n continua:

```python
# Entrenar con ventana mÃ³vil
window_size = 365  # 1 aÃ±o
for i in range(window_size, len(df)):
    train_data = df.iloc[i-window_size:i]
    test_point = df.iloc[i]
    # Entrenar, predecir, evaluar
```

## ğŸš€ CÃ³mo Usar Este Proyecto

### Requisitos

```bash
pip install pandas numpy scikit-learn matplotlib seaborn
```

### EjecuciÃ³n

1. Navegar a la carpeta:
```bash
cd projects/temporal-split
```

2. Abrir el notebook:
```bash
jupyter notebook data_leakage_temporal.ipynb
```

3. Ejecutar las celdas y observar las diferencias entre ambos enfoques.

## ğŸ“ Contenido del Notebook

1. **GeneraciÃ³n de datos sintÃ©ticos** de ventas con tendencia y estacionalidad
2. **Split aleatorio (incorrecto)** y evaluaciÃ³n
3. **VisualizaciÃ³n del data leakage** en el tiempo
4. **Split temporal (correcto)** y evaluaciÃ³n
5. **ComparaciÃ³n de mÃ©tricas** entre ambos enfoques
6. **Uso de TimeSeriesSplit** para validaciÃ³n cruzada temporal

## ğŸ’¡ Conclusiones Clave

1. **NUNCA uses `train_test_split` con `shuffle=True` en datos temporales**
2. **Respeta siempre el orden cronolÃ³gico**: train = pasado, test = futuro
3. **Las mÃ©tricas optimistas son peligrosas** - prefiere mÃ©tricas conservadoras y realistas
4. **Usa `TimeSeriesSplit`** para validaciÃ³n cruzada en series de tiempo
5. **Simula producciÃ³n**: tu split debe reflejar cÃ³mo usarÃ¡s el modelo en la vida real

## ğŸ“š Referencias

- [Scikit-learn: TimeSeriesSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html)
- [Avoiding Data Leakage in Time Series](https://machinelearningmastery.com/data-leakage-machine-learning/)
- [Time Series Cross-Validation](https://towardsdatascience.com/time-series-nested-cross-validation-76adba623eb9)

## ğŸ‘¨â€ğŸ« Para Instructores

Este material es ideal para:
- Cursos de Machine Learning aplicado
- MÃ³dulos sobre validaciÃ³n de modelos
- Talleres sobre series de tiempo
- Discusiones sobre buenas prÃ¡cticas en ML

**DuraciÃ³n estimada**: 60-75 minutos

**Conceptos relacionados**:
- Feature engineering temporal
- Lag features
- Walk-forward validation
- Backtesting

---

**Licencia**: MIT License
**Autor**: David Palacio JimÃ©nez
